# -*- coding: utf-8 -*-
"""PRML_assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v9gCpXcxX9nJ_9IUWsEu3KuF7sedKhKI

Authors:
V S S Anirudh Sharma, EE18B036
Hema Landa, EE19B036    
"""

import sys
import matplotlib.pyplot as plt
import numpy as np

"""## Functions"""

def extract1Ddata(fileName,delim = ' '):
  f = open(fileName, "r")
  data = f.readlines()
  f.close()
  X_all = []
  Y_all = []
  for d in data:
    X,Y= map(float,d[:].split(delim))
    X_all.append(X)
    Y_all.append(Y)
  return X_all,Y_all

def extract2Ddata(fileName,delim = ' '):
  f = open(fileName, "r")
  data = f.readlines()
  f.close()
  X_all = []
  Y_all = []
  for d in data:
    X1,X2,Y= map(float,d[:].split(delim))
    X_all.append([X1,X2])
    Y_all.append(Y)
  return X_all,Y_all

def sampleData(X_all,Y_all,N):
  select = [int(i) for i in np.linspace(0,len(Y_all)-1,N)]
  X = np.array([X_all[i] for i in select])
  Y = np.array([Y_all[i] for i in select])
  return X,Y

def polyfit1D(X1,Y1,order = 2, lam = 0):
  X = np.array([[x**i for i in range(order+1)] for x in X1])
  W = np.linalg.inv(X.T@X+lam*np.eye(X.shape[1]))@X.T@Y1
  Y_fit = X@W
  return W, Y_fit

def polyfit2D(X1,Y1,order = 2, lam = 0):
  powers = [[[i,d-i] for i in range(d+1)] for d in range(order+1)]
  powers = np.concatenate([i for i in powers])
  X = np.array([[x[0]**p*x[1]**q for [p,q] in powers] for x in X1])
  W = np.linalg.inv(X.T@X+lam*np.eye(X.shape[1]))@X.T@Y1
  Y_fit = X@W
  return W, Y_fit



# Extracting Data from files:
try:
  Xtrain1_all, Ytrain1_all = extract1Ddata(sys.argv[1])
  Xdev1_all, Ydev1_all = extract1Ddata(sys.argv[2])
  Xtrain2_all, Ytrain2_all = extract2Ddata(sys.argv[3])
  Xdev2_all, Ydev2_all = extract2Ddata(sys.argv[4])  
except:
  print('Invalid arguments')
  exit()  

#--------------------------------------------------------------------------------------------------  

"""# 1 D dataset"""

Xtrain1, Ytrain1 = sampleData(Xtrain1_all,Ytrain1_all,200)
Xdev1, Ydev1 = sampleData(Xdev1_all,Ydev1_all,200)

plt.figure(figsize=(10,5))
plt.scatter(Xtrain1,Ytrain1,label = 'training')
plt.scatter(Xdev1,Ydev1,label ='dev')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.title('Sampled Data')


"""#Curve fitting

# No reg
"""


"""## Finding optimal order"""

orders = [i for i in range(12)]
Y_fits = {}
Ws = {}
for order in orders:
   Ws[order] ,Y_fits[order] = polyfit1D(Xtrain1,Ytrain1,order)

Y_fits_dev = {}
for order in orders:
  X = np.array([[x**i for i in range(order+1)] for x in Xdev1])
  Y_fit = X@Ws[order]
  Y_fits_dev[order] = (Y_fit)

fig = plt.figure(figsize = (20,10))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
for order in range(4):
    ax = fig.add_subplot(2, 2, order+1)
    ax.plot(Xdev1,Y_fits_dev[min(int(order*3.5),11)],label = 'order={}'.format(min(int(order*3.5),11)))
    ax.scatter(Xtrain1,Ytrain1,label = 'Train',c = 'g',s=10)
    ax.scatter(Xdev1,Ydev1,label = 'Dev',c = 'r',s=5)
    ax.set_xlabel('X')
    ax.set_title('Polynomial fit order = {}'.format(min(int(order*3.5),11)))
    ax.set_ylabel('Y')
    ax.legend()

plt.figure(figsize = (10,10))
plt.scatter(Xtrain1,Ytrain1,label = 'original',c='r')
for order in orders:
  plt.plot(Xtrain1,Y_fits[order],label = 'order={}'.format(order))
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Training data fit for different order polynomials')
plt.legend()

plt.figure(figsize = (10,10))
plt.scatter(Xdev1,Ydev1,label = 'original')
for order in orders:
  plt.plot(Xdev1,Y_fits_dev[order],label = 'order={}'.format(order))
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Development data fit for different order polynomials')
plt.legend()

dev_errors = [np.linalg.norm(Y_fits_dev[order]-Ydev1) for order in orders]

train_errors = [np.linalg.norm(Y_fits[order]-Ytrain1) for order in orders]

offset = 2
plt.figure(figsize=(10,5))
plt.plot(orders[offset:],dev_errors[offset:],label = 'dev')
plt.plot(orders[offset:],dev_errors[offset:],'*')
plt.plot(orders[offset:],train_errors[offset:],label = 'train')
plt.plot(orders[offset:],train_errors[offset:],'*')
plt.xlabel('order of polynomial')
plt.ylabel('$E_{rms}$')
plt.grid()
plt.legend()
plt.title('Errors vs order')

"""# Optimal order fit over different sample sizes"""

Ns = [15,50,100,200]
fig = plt.figure(figsize = (20,10))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
im = 1;
order = 10
Xtest1 = np.linspace(0,5,100)
Xtest2 = np.array([[x**i for i in range(order + 1)] for x in Xtest1]) 

for N in Ns:
  XtrainN, YtrainN = sampleData(Xtrain1_all,Ytrain1_all,N)
  XdevN, YdevN = sampleData(Xdev1_all,Ydev1_all,N)
  WN ,_ = polyfit1D(XtrainN,YtrainN,order)

  Y_fit = Xtest2@WN
  ax = fig.add_subplot(2, 2, im)
  ax.scatter(XtrainN,YtrainN,label = 'train',c = 'g',s= 20)
  ax.scatter(XdevN,YdevN,label = 'Dev',c = 'r',s = 10)
  ax.plot(Xtest1,Y_fit,'b',label = 'order {} poly fit'.format(order))
  ax.set_xlabel('X')
  ax.set_title('Development data polynomial fit, N = {}'.format(N))
  ax.set_ylabel('Y')
  ax.legend()      
  im+=1

"""# L2 Regularization"""

order = 10; lams = [10**i for i in range(-7,1)]

Xdev = np.array([[x**i for i in range(order+1)] for x in Xdev1])
lam_err_train = []
lam_err_dev = []
for lam in lams:
  W, Y_fit = polyfit1D(Xtrain1,Ytrain1,order,lam)
  Y_fit_dev = Xdev@W
  lam_err_train.append(np.linalg.norm(Y_fit-Ytrain1))
  lam_err_dev.append(np.linalg.norm(Y_fit_dev-Ydev1))

plt.figure(figsize = (10,10))
plt.semilogx(lams,lam_err_train,label = 'train')
plt.semilogx(lams,lam_err_dev,label = 'dev')
plt.xlabel('$\lambda$ (regularization parameter)')
plt.ylabel('$E_{rms}$')
plt.title('Finding $\lambda$')
plt.legend()


## Visualizing fits for different lambdas
fig = plt.figure(figsize = (20,10))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
im = 1;
order = 10
Xfit1 = np.linspace(0,5,100)
Xfit2 = np.array([[x**i for i in range(order + 1)] for x in Xtest1]) 
lams = [1e-18,1e-5,1e-3,1]

for lam in lams:
  
  WN ,_ = polyfit1D(XtrainN,YtrainN,order,lam)

  Y_fit = Xfit2@WN
  ax = fig.add_subplot(2, 2, im)
  
  ax.scatter(Xtrain1,Ytrain1,label = 'train',c = 'g',s= 20)
  ax.scatter(Xdev1,Ydev1,label = 'dev',c = 'r',s = 10)
  ax.plot(Xfit1,Y_fit,'b',label = 'order {} poly fit'.format(order))
  ax.set_xlabel('X')
  ax.set_title('Development data polynomial fit, lambda = {}'.format(lam))
  ax.set_ylabel('Y')
  ax.legend()      
  im+=1

degree = 10; lam = 1e-5
X = np.array([[x**i for i in range(degree+1)] for x in Xtrain1])
X_dev = np.array([[x**i for i in range(degree+1)] for x in Xdev1])
#print(np.linalg.cond(X))
#W = np.linalg.pinv(X)@Ytrain1
#W = np.linalg.inv(X.T@X)@X.T@Ytrain1
W, YfitTra= polyfit1D(Xtrain1,Ytrain1,order,lam)
Xtest1 = np.linspace(0,5,100)
Xtest2 = np.array([[x**i for i in range(order + 1)] for x in Xtest1]) 
XdevPly = np.array([[x**i for i in range(order + 1)] for x in Xdev1]) 
Y_fit = Xtest2@W
YfitDev = XdevPly@W
plt.figure(figsize=(10,5))
plt.scatter(Xtrain1,Ytrain1,label = 'train',s = 20)
plt.scatter(Xdev1,Ydev1,label = 'dev',s = 10)
plt.plot(Xtest1,Y_fit,'g-',label = 'fit')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Final fit with regularization')
plt.legend()

print('\n\n_________________________________________________')
print('1 D DATA')
print("Final model order = {}, reg parameter = {}".format(degree,lam))
print("Training data fit Error\t= {}".format(np.linalg.norm(Ytrain1-YfitTra)))
print("Development data fir Error\t= {}".format(np.linalg.norm(Ydev1-YfitDev)))
print('_________________________________________________\n\n')



#--------------------------------------------------------------------------------------------------------------------------

"""# 2D data"""


Xtrain2, Ytrain2 = sampleData(Xtrain2_all,Ytrain2_all,1000)
Xdev2, Ydev2 = sampleData(Xdev2_all,Ydev2_all,1000)


# In[124]:


n = 50;
x = np.linspace(-1,1); X,Y = np.meshgrid(x,x); 


# In[125]:


fig = plt.figure(figsize = (10,10))
ax = plt.axes(projection='3d')
ax.scatter3D(Xtrain2[:,0], Xtrain2[:,1], Ytrain2,label = 'Training')
ax.scatter3D(Xdev2[:,0], Xdev2[:,1], Ydev2,label='Development')
ax.set_xlabel('$X_1$', fontsize=20)
ax.set_ylabel('$X_2$', fontsize=20)
ax.set_zlabel('$Y$', fontsize=20)
ax.legend()
plt.title('Data samples',fontsize = 30)




# # Curve Fitting

# # No reg


orders = [i for i in range(20)]

Y_fits2 = {order:np.zeros((n,n)) for order in orders}
Ws2 = {}

powers = {order:[[[i,d-i] for i in range(d+1)] for d in range(order+1)] for order in orders}
powers = {order: np.concatenate([i for i in powers[order]]) for order in orders}
for order in orders:
  Ws2[order], _ = polyfit2D(Xtrain2,Ytrain2,order)
  X1 = np.array([[x**p*y**q for [p,q] in powers[order]] for x,y in zip(X,Y) ])
  Y_fit = np.zeros((n,n))
  for p in range(n):
    for q in range(n): 
      Y_fits2[order][p,q] = X1[p,:,q]@Ws2[order]


# In[134]:


fig = plt.figure(figsize = (18,18))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
for order in range(4):
    ax = fig.add_subplot(2, 2, order+1, projection = '3d')

    c = ax.plot_surface(X,Y,Y_fits2[min(int(order*6),19)], cstride=1, rstride=1,alpha = 0.5,label = 'fit')
    c._facecolors2d=c._facecolors3d
    c._edgecolors2d=c._edgecolors3d
    #ax.scatter3D(Xtrain2[:,0], Xtrain2[:,1], Y_fits2[min(int(order*6),19)],label = 'degree={}'.format(min(int(order*6),19)))
    ax.scatter3D(Xtrain2[:,0], Xtrain2[:,1], Ytrain2,label = 'Train') 
    ax.scatter3D(Xdev2[:,0], Xdev2[:,1], Ydev2,label = 'Dev') 
    ax.set_xlabel('X')
    ax.set_title('Data polynomial fit order = {}'.format(min(int(order*6),19)))
    ax.set_ylabel('Y')
    ax.legend()      


# ## Finding optimal degree

# In[51]:


Y_fits_dev2 = {}
Y_fits_tra2 = {}
for degree in orders:
  Xt = np.array([[x[0]**p*x[1]**q for [p,q] in powers[degree]] for x in Xtrain2])
  Xd = np.array([[x[0]**p*x[1]**q for [p,q] in powers[degree]] for x in Xdev2])

  #X = np.array([[x**i for i in range(degree+1)] for x in Xdev1])
  #W = np.linalg.pinv(X)@Ytrain1
  Y_fit = Xd@Ws2[degree]
  Y_fits_dev2[degree] = (Y_fit)
  Y_fit = Xt@Ws2[degree]
  Y_fits_tra2[degree] = (Y_fit)


# In[54]:


dev_errors = [np.linalg.norm(Y_fits_dev2[degree]-Ydev2) for degree in orders]


# In[55]:


train_errors = [np.linalg.norm(Y_fits_tra2[degree]-Ytrain2) for degree in orders]


# In[56]:


offset = 2
plt.figure(figsize=(10,5))
plt.plot(orders[offset:],dev_errors[offset:],label = 'dev')
plt.plot(orders[offset:],dev_errors[offset:],'*')
plt.plot(orders[offset:],train_errors[offset:],label = 'train')
plt.plot(orders[offset:],train_errors[offset:],'*')
plt.xlabel('order of polynomial')
plt.ylabel('$E_{rms}$')
plt.grid()
plt.legend()
plt.title('Errors vs order')


# # Different Sample Sizes

# In[105]:


Ns = [15,50,100,200]
fig = plt.figure(figsize = (20,20))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
im = 1;
order = 11
#Z = np.array([X,Y])
#print(Z.shape)


X1 = np.array([[x**p*y**q for [p,q] in powers[order]] for x,y in zip(X,Y) ])


for N in Ns:
  XtrainN, YtrainN = sampleData(Xtrain2_all,Ytrain2_all,N)
  XdevN, YdevN = sampleData(Xdev2_all,Ydev2_all,N)
  WN , _ = polyfit2D(XtrainN,YtrainN,order)

  ax = fig.add_subplot(2, 2, im,projection = '3d')
  
  Y_fit = np.zeros((n,n))
  for i in range(n):
    for j in range(n):
      Y_fit[i,j] = X1[i,:,j]@WN
  
  c = ax.plot_surface(X,Y,Y_fit.reshape(n,n), cstride=1, rstride=1,alpha = 0.5,label = 'fit')
  c._facecolors2d=c._facecolors3d
  c._edgecolors2d=c._edgecolors3d
  ax.scatter3D(XtrainN[:,0],XtrainN[:,1],YtrainN,label = 'train',c = 'g',s= 20)
  ax.scatter3D(XdevN[:,0],XdevN[:,1],YdevN,label = 'Dev',c = 'r',s = 10)
  #ax.scatter3D(XtrainN[:,0],XtrainN[:,1],Y_fit,'b',label = 'order {} poly fit'.format(order))
  #ax.contour(X,Y,Y_fit.reshape(n,n))
  
  ax.set_xlabel('X1')
  ax.set_title('Development data polynomial fit, N = {}'.format(N))
  ax.set_ylabel('X2')
  ax.legend()      
  im+=1


# # L2 Regularization

# In[57]:


order = 11; lams = [10**i for i in range(-10,1)]
#X = np.array([[x[0]**p*x[1]**q for [p,q] in powers[degree]] for x in Xtrain1])
Xdev = np.array([[x[0]**p*x[1]**q for [p,q] in powers[order]] for x in Xdev2])
#X = np.array([[x**i for i in range(degree+1)] for x in Xtrain1])
#Xdev = np.array([[x**i for i in range(degree+1)] for x in Xdev1])
lam_err_train = []
lam_err_dev = []
for lam in lams:
  #W = np.linalg.inv(X.T@X+lam*np.eye(X.shape[1]))@X.T@Ytrain1
  #Y_fit = X@W
  W, Y_fit = polyfit2D(Xtrain2,Ytrain2,order,lam)
  Y_fit_dev = Xdev@W
  lam_err_train.append(np.linalg.norm(Y_fit-Ytrain2))
  lam_err_dev.append(np.linalg.norm(Y_fit_dev-Ydev2))


# In[58]:


plt.figure(figsize = (10,10))
plt.semilogx(lams,lam_err_train,label = 'train')
plt.semilogx(lams,lam_err_dev,label = 'dev')
plt.xlabel('$\lambda$ (regularization parameter)')
plt.ylabel('$E_{rms}$')
plt.title('Finding $\lambda$')
plt.legend()
plt.grid()


# In[104]:


fig = plt.figure(figsize = (20,20))
fig.subplots_adjust(hspace=0.4, wspace=0.4)
order = 11

lams = [1e-18,1e-6,1e-3,1]
for i in range(1,5):

  WN ,_ = polyfit2D(Xtrain2,Ytrain2,order,lams[i-1])

  ax = fig.add_subplot(2, 2, i, projection = '3d')
  Y_fit = np.zeros((n,n))
  for p in range(n):
    for q in range(n):
      Y_fit[p,q] = X1[p,:,q]@WN
  
  c = ax.plot_surface(X,Y,Y_fit.reshape(n,n), cstride=1, rstride=1,alpha = 0.5,label = 'fit')
  c._facecolors2d=c._facecolors3d
  c._edgecolors2d=c._edgecolors3d
  ax.scatter3D(Xtrain2[:,0], Xtrain2[:,1], Ytrain2,label = 'training data')
  ax.scatter3D(Xdev2[:,0], Xdev2[:,1], Ydev2,label = 'dev data')
  ax.set_xlabel('X')
  ax.set_title('Polynomial fit order = {}, reg param = {}'.format(order,lams[i-1]))
  ax.set_ylabel('Y')
  ax.legend() 




## Final fit
lam = 1e-6
W, Y_fit_tra = polyfit2D(Xtrain2,Ytrain2,order,lam)
Xdev = np.array([[x[0]**p*x[1]**q for [p,q] in powers[order]] for x in Xdev2])
Y_fit_dev = Xdev@W

Y_fit = np.zeros((n,n))
for i in range(n):
  for j in range(n):
    Y_fit[i,j] = X1[i,:,j]@W
  


fig = plt.figure(figsize = (10,10))
ax = plt.axes(projection='3d')
c = ax.plot_surface(X,Y,Y_fit.reshape(n,n), cstride=1, rstride=1,alpha = 0.5,label = 'fit')
c._facecolors2d=c._facecolors3d
c._edgecolors2d=c._edgecolors3d
ax.scatter3D(Xdev2[:,0], Xdev2[:,1], Ydev2, label = 'dev')
ax.scatter3D(Xtrain2[:,0], Xtrain2[:,1], Ytrain2,label = 'train')

ax.set_xlabel('$X$', fontsize=20)
ax.set_ylabel('$Y$')
ax.legend()
plt.title('Final fit after regularization',fontsize = 20)


# In[66]:




print('\n\n_________________________________________________')
print('2 D DATA')
print("Final model order = {}, reg parameter = {}".format(order,lam))
print("Training data fit Error\t= {}".format(np.linalg.norm(Ytrain2-Y_fit_tra)))
print("Development data fir Error\t= {}".format(np.linalg.norm(Ydev2-Y_fit_dev)))
print('_________________________________________________\n\n')


plt.show()